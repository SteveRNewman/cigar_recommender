{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run this book 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn. __version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review = pd.read_pickle('reviews_all.pkl')\n",
    "# df_review['review_body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prod_name          0\n",
       "rating             8\n",
       "rating_count      86\n",
       "desc               0\n",
       "profile           46\n",
       "vitolas            0\n",
       "Binder           482\n",
       "Filler           116\n",
       "Flavored           2\n",
       "Has Tip           68\n",
       "Origin            18\n",
       "Pressed            2\n",
       "Profile         1340\n",
       "Shapes            12\n",
       "Sweet              2\n",
       "Wrapper           14\n",
       "Brand:           341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = pd.read_pickle('../data/working_data/df_main.pkl')\n",
    "df_main.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    " \n",
    "\n",
    "s = df_main['vitolas']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "df_vitola = pd.DataFrame(mlb.fit_transform(s),columns= (f'vitola_' + mlb.classes_), index=df_main.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_vitola' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_vitola\n",
    "#del df_vitola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_vitola = pd.concat([df_main, df_vitola], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KNN = df_main_vitola.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prod_name                     0\n",
       "rating                        8\n",
       "rating_count                 86\n",
       "desc                          0\n",
       "profile                      46\n",
       "vitolas                       0\n",
       "Binder                      482\n",
       "Filler                      116\n",
       "Flavored                      2\n",
       "Has Tip                      68\n",
       "Origin                       18\n",
       "Pressed                       2\n",
       "Profile                    1340\n",
       "Shapes                       12\n",
       "Sweet                         2\n",
       "Wrapper                      14\n",
       "Brand:                      341\n",
       "vitola_Belicoso               0\n",
       "vitola_Churchill              0\n",
       "vitola_Cigarillos             0\n",
       "vitola_Corona                 0\n",
       "vitola_Corona Especial        0\n",
       "vitola_Corona Extra           0\n",
       "vitola_Corona Gigante         0\n",
       "vitola_Corona Gordo           0\n",
       "vitola_Corona Grande          0\n",
       "vitola_Culebra                0\n",
       "vitola_Double Corona          0\n",
       "vitola_Double Perfecto        0\n",
       "vitola_Double Robusto         0\n",
       "vitola_Double Toro            0\n",
       "vitola_Figurado               0\n",
       "vitola_Gigante                0\n",
       "vitola_Gordo                  0\n",
       "vitola_Gordo Extra            0\n",
       "vitola_Gran Rothschild        0\n",
       "vitola_Lancero                0\n",
       "vitola_Lancero/Panatela       0\n",
       "vitola_Lonsdale               0\n",
       "vitola_Panatela               0\n",
       "vitola_Perfecto               0\n",
       "vitola_Petite Corona          0\n",
       "vitola_Presidente             0\n",
       "vitola_Pyramid                0\n",
       "vitola_Robusto                0\n",
       "vitola_Robusto Extra          0\n",
       "vitola_Rothschild             0\n",
       "vitola_Salomon                0\n",
       "vitola_Short Robusto          0\n",
       "vitola_Toro                   0\n",
       "vitola_Torpedo                0\n",
       "vitola_Wedge                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_KNN.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KNN1 = df_KNN.drop(['vitolas', 'Shapes','prod_name', 'rating', 'rating_count', 'desc', 'Profile'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF to Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_KNN1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_KNN1.to_pickle('../data/working_data/KNN1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profile                     46\n",
       "Binder                     482\n",
       "Filler                     116\n",
       "Flavored                     2\n",
       "Has Tip                     68\n",
       "Origin                      18\n",
       "Pressed                      2\n",
       "Sweet                        2\n",
       "Wrapper                     14\n",
       "Brand:                     341\n",
       "vitola_Belicoso              0\n",
       "vitola_Churchill             0\n",
       "vitola_Cigarillos            0\n",
       "vitola_Corona                0\n",
       "vitola_Corona Especial       0\n",
       "vitola_Corona Extra          0\n",
       "vitola_Corona Gigante        0\n",
       "vitola_Corona Gordo          0\n",
       "vitola_Corona Grande         0\n",
       "vitola_Culebra               0\n",
       "vitola_Double Corona         0\n",
       "vitola_Double Perfecto       0\n",
       "vitola_Double Robusto        0\n",
       "vitola_Double Toro           0\n",
       "vitola_Figurado              0\n",
       "vitola_Gigante               0\n",
       "vitola_Gordo                 0\n",
       "vitola_Gordo Extra           0\n",
       "vitola_Gran Rothschild       0\n",
       "vitola_Lancero               0\n",
       "vitola_Lancero/Panatela      0\n",
       "vitola_Lonsdale              0\n",
       "vitola_Panatela              0\n",
       "vitola_Perfecto              0\n",
       "vitola_Petite Corona         0\n",
       "vitola_Presidente            0\n",
       "vitola_Pyramid               0\n",
       "vitola_Robusto               0\n",
       "vitola_Robusto Extra         0\n",
       "vitola_Rothschild            0\n",
       "vitola_Salomon               0\n",
       "vitola_Short Robusto         0\n",
       "vitola_Toro                  0\n",
       "vitola_Torpedo               0\n",
       "vitola_Wedge                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_KNN1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "imputer = IterativeImputer(ExtraTreesRegressor())\n",
    "inv_tran = []\n",
    "# create a list of categorical columns to iterate over\n",
    "cat_cols = ['profile','Binder','Filler','Flavored','Has Tip','Origin','Pressed','Sweet','Wrapper', 'Brand:']\n",
    "\n",
    "def encode(data):\n",
    "    '''function to encode non-null data and replace it in the original data'''\n",
    "    #retains only non-null values\n",
    "    nonulls = np.array(data.dropna())\n",
    "    #reshapes the data for encoding\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Encoder Dict\n",
    "    inverse_trans = inv_tran.append(encoder.categories_)\n",
    "    #Assign back encoded values to non-null values\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "#create a for loop to iterate through each column in the data\n",
    "for columns in cat_cols:\n",
    "    encode(df_KNN1[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'inv_tran' (list)\n"
     ]
    }
   ],
   "source": [
    "%store inv_tran\n",
    "#del inv_tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>Binder</th>\n",
       "      <th>Filler</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Has Tip</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Pressed</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Wrapper</th>\n",
       "      <th>Brand:</th>\n",
       "      <th>vitola_Belicoso</th>\n",
       "      <th>vitola_Churchill</th>\n",
       "      <th>vitola_Cigarillos</th>\n",
       "      <th>vitola_Corona</th>\n",
       "      <th>vitola_Corona Especial</th>\n",
       "      <th>vitola_Corona Extra</th>\n",
       "      <th>vitola_Corona Gigante</th>\n",
       "      <th>vitola_Corona Gordo</th>\n",
       "      <th>vitola_Corona Grande</th>\n",
       "      <th>vitola_Culebra</th>\n",
       "      <th>vitola_Double Corona</th>\n",
       "      <th>vitola_Double Perfecto</th>\n",
       "      <th>vitola_Double Robusto</th>\n",
       "      <th>vitola_Double Toro</th>\n",
       "      <th>vitola_Figurado</th>\n",
       "      <th>vitola_Gigante</th>\n",
       "      <th>vitola_Gordo</th>\n",
       "      <th>vitola_Gordo Extra</th>\n",
       "      <th>vitola_Gran Rothschild</th>\n",
       "      <th>vitola_Lancero</th>\n",
       "      <th>vitola_Lancero/Panatela</th>\n",
       "      <th>vitola_Lonsdale</th>\n",
       "      <th>vitola_Panatela</th>\n",
       "      <th>vitola_Perfecto</th>\n",
       "      <th>vitola_Petite Corona</th>\n",
       "      <th>vitola_Presidente</th>\n",
       "      <th>vitola_Pyramid</th>\n",
       "      <th>vitola_Robusto</th>\n",
       "      <th>vitola_Robusto Extra</th>\n",
       "      <th>vitola_Rothschild</th>\n",
       "      <th>vitola_Salomon</th>\n",
       "      <th>vitola_Short Robusto</th>\n",
       "      <th>vitola_Toro</th>\n",
       "      <th>vitola_Torpedo</th>\n",
       "      <th>vitola_Wedge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile  Binder  Filler  Flavored  Has Tip  Origin  Pressed  Sweet  Wrapper  Brand:  vitola_Belicoso  vitola_Churchill  vitola_Cigarillos  vitola_Corona  vitola_Corona Especial  vitola_Corona Extra  vitola_Corona Gigante  vitola_Corona Gordo  vitola_Corona Grande  vitola_Culebra  vitola_Double Corona  vitola_Double Perfecto  vitola_Double Robusto  vitola_Double Toro  vitola_Figurado  vitola_Gigante  vitola_Gordo  vitola_Gordo Extra  vitola_Gran Rothschild  vitola_Lancero  vitola_Lancero/Panatela  vitola_Lonsdale  vitola_Panatela  vitola_Perfecto  vitola_Petite Corona  vitola_Presidente  vitola_Pyramid  vitola_Robusto  vitola_Robusto Extra  vitola_Rothschild  vitola_Salomon  vitola_Short Robusto  vitola_Toro  vitola_Torpedo  vitola_Wedge\n",
       "0      3.0    61.0    38.0       0.0      1.0     2.0      0.0    0.0     27.0    28.0              0.0               1.0                0.0            0.0                     0.0                  0.0                    0.0                  0.0                   0.0             0.0                   0.0                     0.0                    0.0                 0.0              0.0             0.0           0.0                 0.0                     0.0             0.0                      0.0              0.0              0.0              0.0                   0.0                0.0             0.0             1.0                   0.0                0.0             0.0                   0.0          1.0             1.0           0.0\n",
       "1      4.0    35.0    38.0       0.0      1.0     2.0      0.0    0.0    156.0     8.0              0.0               1.0                0.0            0.0                     0.0                  0.0                    0.0                  0.0                   0.0             0.0                   0.0                     0.0                    0.0                 0.0              0.0             0.0           0.0                 0.0                     0.0             0.0                      0.0              0.0              0.0              0.0                   0.0                0.0             0.0             1.0                   0.0                0.0             0.0                   0.0          1.0             1.0           0.0\n",
       "2      4.0    34.0    38.0       0.0      1.0     2.0      0.0    0.0     27.0    26.0              0.0               1.0                0.0            1.0                     0.0                  0.0                    0.0                  0.0                   0.0             0.0                   0.0                     0.0                    0.0                 0.0              0.0             0.0           0.0                 0.0                     0.0             0.0                      0.0              0.0              0.0              0.0                   0.0                0.0             0.0             1.0                   0.0                0.0             0.0                   0.0          0.0             0.0           0.0\n",
       "3      1.0    56.0    84.0       0.0      1.0    13.0      0.0    0.0    135.0     0.0              0.0               1.0                0.0            0.0                     0.0                  0.0                    0.0                  0.0                   0.0             0.0                   0.0                     0.0                    0.0                 0.0              0.0             0.0           1.0                 0.0                     0.0             0.0                      0.0              0.0              0.0              0.0                   0.0                0.0             0.0             0.0                   0.0                0.0             0.0                   0.0          0.0             1.0           0.0\n",
       "4      2.0    56.0    67.0       0.0      1.0    13.0      1.0    0.0     68.0     0.0              0.0               0.0                0.0            0.0                     0.0                  0.0                    0.0                  0.0                   0.0             0.0                   0.0                     0.0                    0.0                 0.0              0.0             0.0           1.0                 0.0                     0.0             0.0                      0.0              0.0              0.0              0.0                   0.0                0.0             0.0             0.0                   0.0                0.0             0.0                   0.0          1.0             0.0           0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute data and convert \n",
    "encode_data = pd.DataFrame(np.round(imputer.fit_transform(df_KNN1)),columns = df_KNN1.columns)\n",
    "encode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode_data.to_pickle('../data/working_data/encode_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 45)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_KNN1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_data2 = pd.DataFrame(encode_data, columns=df_KNN1.columns)\n",
    "# encode_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute data and convert \n",
    "encode_data[list(cat_cols)] = encode_data[list(cat_cols)].astype(int)\n",
    "\n",
    "\n",
    "#encode_data.dtypes\n",
    "df = encode_data[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>Binder</th>\n",
       "      <th>Filler</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Has Tip</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Pressed</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Wrapper</th>\n",
       "      <th>Brand:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1339</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      profile  Binder  Filler  Flavored  Has Tip  Origin  Pressed  Sweet  Wrapper  Brand:\n",
       "0           3      61      38         0        1       2        0      0       27      28\n",
       "1           4      35      38         0        1       2        0      0      156       8\n",
       "2           4      34      38         0        1       2        0      0       27      26\n",
       "3           1      56      84         0        1      13        0      0      135       0\n",
       "4           2      56      67         0        1      13        1      0       68       0\n",
       "...       ...     ...     ...       ...      ...     ...      ...    ...      ...     ...\n",
       "1335        3      56      84         0        1      13        0      0       27      19\n",
       "1336        3      36      48         0        1      17        0      1      117      47\n",
       "1337        2      15      42         0        1       8        0      0       29      49\n",
       "1338        2       6      59         0        1       2        0      0       88      36\n",
       "1339        1      22      47         0        1       6        0      0        0      65\n",
       "\n",
       "[1340 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile\n",
      "Binder\n",
      "Filler\n",
      "Flavored\n",
      "Has Tip\n",
      "Origin\n",
      "Pressed\n",
      "Sweet\n",
      "Wrapper\n",
      "Brand:\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['profile','Binder','Filler','Flavored','Has Tip','Origin','Pressed','Sweet','Wrapper', 'Brand:']\n",
    "\n",
    "categorical_columns = cat_cols\n",
    "for i,column in enumerate(categorical_columns):\n",
    "    label_list = inv_tran[i][0]\n",
    "    df[column] = [label_list[j] for j in df[column]]\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>Binder</th>\n",
       "      <th>Filler</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Has Tip</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Pressed</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Wrapper</th>\n",
       "      <th>Brand:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mellow</td>\n",
       "      <td>Sumatra</td>\n",
       "      <td>Dominican</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Djarum Filtered Cigars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mellow-Medium</td>\n",
       "      <td>Dominican, Ecuador</td>\n",
       "      <td>Dominican</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Maduro</td>\n",
       "      <td>Arturo Fuente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mellow-Medium</td>\n",
       "      <td>Dominican</td>\n",
       "      <td>Dominican</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Davidoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Nicaraguan</td>\n",
       "      <td>Nicaraguan</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Habano, Nicaraguan</td>\n",
       "      <td>5 Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Medium-Full</td>\n",
       "      <td>Nicaraguan</td>\n",
       "      <td>Honduran, Nicaraguan</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Corojo</td>\n",
       "      <td>5 Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>Mellow</td>\n",
       "      <td>Nicaraguan</td>\n",
       "      <td>Nicaraguan</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Camacho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>Mellow</td>\n",
       "      <td>Dominican, Habano</td>\n",
       "      <td>Dominican, Honduran, Peruvian</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>HTL</td>\n",
       "      <td>Kristoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>Medium-Full</td>\n",
       "      <td>Connecticut, Mexican</td>\n",
       "      <td>Dominican, Honduran</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Connecticut Broadleaf, Corojo, Sumatra</td>\n",
       "      <td>La Aroma de Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338</td>\n",
       "      <td>Medium-Full</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Dominican, Peruvian</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ecuador Connecticut</td>\n",
       "      <td>Foundation Cigar Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1339</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Corojo, Nicaraguan</td>\n",
       "      <td>Dominican, Honduran, Nicaraguan, United States</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Brazilian</td>\n",
       "      <td>Perdomo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            profile                Binder                                          Filler Flavored Has Tip              Origin Pressed  Sweet                                 Wrapper                    Brand:\n",
       "0            Mellow               Sumatra                                       Dominican    False      No  Dominican Republic   False  False                             Connecticut    Djarum Filtered Cigars\n",
       "1     Mellow-Medium    Dominican, Ecuador                                       Dominican    False      No  Dominican Republic   False  False                                  Maduro             Arturo Fuente\n",
       "2     Mellow-Medium             Dominican                                       Dominican    False      No  Dominican Republic   False  False                             Connecticut                  Davidoff\n",
       "3            Medium            Nicaraguan                                      Nicaraguan    False      No           Nicaragua   False  False                      Habano, Nicaraguan                   5 Vegas\n",
       "4       Medium-Full            Nicaraguan                            Honduran, Nicaraguan    False      No           Nicaragua    True  False                                  Corojo                   5 Vegas\n",
       "...             ...                   ...                                             ...      ...     ...                 ...     ...    ...                                     ...                       ...\n",
       "1335         Mellow            Nicaraguan                                      Nicaraguan    False      No           Nicaragua   False  False                             Connecticut                   Camacho\n",
       "1336         Mellow     Dominican, Habano                   Dominican, Honduran, Peruvian    False      No       United States   False   True                                     HTL                  Kristoff\n",
       "1337    Medium-Full  Connecticut, Mexican                             Dominican, Honduran    False      No            Honduras   False  False  Connecticut Broadleaf, Corojo, Sumatra          La Aroma de Cuba\n",
       "1338    Medium-Full           Connecticut                             Dominican, Peruvian    False      No  Dominican Republic   False  False                     Ecuador Connecticut  Foundation Cigar Company\n",
       "1339         Medium    Corojo, Nicaraguan  Dominican, Honduran, Nicaraguan, United States    False      No              Europe   False  False                               Brazilian                   Perdomo\n",
       "\n",
       "[1340 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('../data/working_data/impute.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impute = pd.read_pickle('../data/working_data/impute.pkl')\n",
    "df_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verify = pd.concat([df_main, df_impute], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verify[['prod_name', 'Filler']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df9 = pd.DataFrame(encoder.categories_)\n",
    "# df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['rating'].fillna( 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['rating_count'].fillna( 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['Has Tip'].fillna( 'No', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_nobrand = df_main.drop('Brand:',1)\n",
    "df_nobrand['is_null'] = df_nobrand.isna().sum(axis=1).apply(lambda x: 0 if x==0 else 1)\n",
    "df_nobrand['is_null'].sum()\n",
    "df_main['is_null'] = df_main.isna().sum(axis=1).apply(lambda x: 0 if x==0 else 1)\n",
    "df_main['is_null'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nobrand = df_main.drop('Brand:',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nobrand['is_null'] = df_nobrand.isna().sum(axis=1).apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nobrand['is_null'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['is_null'] = df_main.isna().sum(axis=1).apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['is_null'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_main[df_main['profile'].isnull()]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_main['Binder'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = df_main\n",
    "# Here we use a column with categorical data\n",
    "fig = px.histogram(df, x=\"Binder\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_main.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main['rating'] = [x.split(' ')[1] if x!=None else x for x in df_main['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main['rating_count'] = [x.split(' ')[3] if x!=None else x for x in df_main['rating_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[[\"prod_name\",\"desc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_process(desc):\n",
    "    \n",
    "    '''tokenize, lower, stopwords, remove punctuation, lemmatizer'''\n",
    "    \n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(desc)\n",
    "    #lower words\n",
    "    lower_words=[word2.lower() for word2 in tokens]\n",
    "    #remove stopwords\n",
    "    stp_words = ([word3 for word3 in lower_words if word3 not in (stopwords.words('english'))])\n",
    "    #remove punctuation\n",
    "    text_without_punct = [s.translate(str.maketrans('', '', string.punctuation)) for s in stp_words]\n",
    "    #lemmatize\n",
    "    lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in text_without_punct]\n",
    "    lemmatizeddf= pd.DataFrame({'original_word': text_without_punct,'lemmatized_word': lemmatized_words})\n",
    "    lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "    return lemmatizeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_process(df_main['desc'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(row):\n",
    "    prod_name = df_main['prod_name'][row]\n",
    "    desc = df_main['desc'][row]\n",
    "    process = df_main['process_desc'][row]\n",
    "    return display(prod_name), display(desc), display(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize df\n",
    "\n",
    "df_main['process_desc'] = df_main.apply(lambda row: nlp_process(row['desc']), axis=1)\n",
    "\n",
    "df_main['desc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize df\n",
    "\n",
    "# df_main['desc'] = df_main.apply(lambda row: nltk.word_tokenize(row['desc']), axis=1)\n",
    "\n",
    "# df_main['desc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token = nltk.word_tokenize(df_main['desc'][0])\n",
    "# token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lower\n",
    "\n",
    "# texts=token\n",
    "# lower_words=[word.lower() for word in texts]\n",
    "# lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stopwords\n",
    "\n",
    "# text = lower_words\n",
    "# stop_words = ([word for word in text if word not in (stopwords.words('english'))])\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(f\"Punctuation symbols: {string.punctuation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "# text_without_punct = [s.translate(str.maketrans('', '', string.punctuation)) for s in stop_words]\n",
    "# text_without_punct = text.translate(str.maketrans('', '', string.punctuation))\n",
    "# display(f\"Text without punctuation: {text_without_punct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize trouble variations\n",
    "\n",
    "# words=text_without_punct\n",
    "# lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in words]\n",
    "# lemmatizeddf= pd.DataFrame({'original_word': words,'lemmatized_word': lemmatized_words})\n",
    "# lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "# lemmatizeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df_main['prod_name']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "tfid_df = pd.DataFrame(X)\n",
    "df_vect = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect.drop([col for col, val in df_vect.mean().iteritems() if val < 0.0025], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vect.to_pickle('../data/working_data/prod_vect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. only keep words w average tfidf scores over 0.0001\n",
    "relevant = []\n",
    "for word in df_vect.columns:\n",
    "    if df_vect[word].mean() > 0.0025:\n",
    "        relevant.append(df_vect[word])\n",
    "len(relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_main, df_vect]\n",
    "\n",
    "result = pd.concat(frames, axis=1)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"desc\"]= df_main[\"desc\"].astype(str) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a list of stopwords to remove\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_words = ['cigar', 'year', 'back', 'time', 'one', 'limited', 'cigars', 'new', 'get'\n",
    "                   ,'years', 'blend','good','La','Gurkha','like','made','Serie', 'classic', 'dark','name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add punctuation to stopwords_list\n",
    "stopwords_list+=string.punctuation\n",
    "## Add additional_words to stopwords_list\n",
    "stopwords_list.extend(additional_words)\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wordcloud = WordCloud(width=800, height=400, stopwords=stopwords_list, background_color=\"white\", max_words=200, \n",
    "                      contour_width=3, \n",
    "                      contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(df_main['desc'].to_string())\n",
    "\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "# def stemming_tokenizer(str_input):\n",
    "#     words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "#     words = [porter_stemmer.stem(word) for word in words]\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def tokenize_and_stem(text):\n",
    "#     # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "#     tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "#     filtered_tokens = []\n",
    "#     # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "#     for token in tokens:\n",
    "#         if re.search('[a-zA-Z]', token):\n",
    "#             filtered_tokens.append(token)\n",
    "#     stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "#     return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# data = df_main['desc']\n",
    "# # data.head()\n",
    "\n",
    "# tf_idf_vectorizor = TfidfVectorizer(stop_words = stopwords,tokenizer = tokenize_and_stem,\n",
    "#                              max_features = 5000)\n",
    "# %time tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
    "# tf_idf_norm = normalize(tf_idf)\n",
    "# tf_idf_array = tf_idf_norm.toarray()\n",
    "# pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_centroids = np.random.permutation(tf_idf_array.shape[0])[:3]\n",
    "# initial_centroids\n",
    "# centroids = tf_idf_array[initial_centroids]\n",
    "# centroids.shape\n",
    "# dist_to_centroid =  pairwise_distances(tf_idf_array,centroids, metric = 'euclidean')\n",
    "# cluster_labels = np.argmin(dist_to_centroid, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Kmeans:\n",
    "#     \"\"\" K Means Clustering\n",
    "    \n",
    "#     Parameters\n",
    "#     -----------\n",
    "#         k: int , number of clusters\n",
    "        \n",
    "#         seed: int, will be randomly set if None\n",
    "        \n",
    "#         max_iter: int, number of iterations to run algorithm, default: 200\n",
    "        \n",
    "#     Attributes\n",
    "#     -----------\n",
    "#        centroids: array, k, number_features\n",
    "       \n",
    "#        cluster_labels: label for each data point\n",
    "       \n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, k, seed = None, max_iter = 200):\n",
    "#         self.k = k\n",
    "#         self.seed = seed\n",
    "#         if self.seed is not None:\n",
    "#             np.random.seed(self.seed)\n",
    "#         self.max_iter = max_iter\n",
    "        \n",
    "            \n",
    "    \n",
    "#     def initialise_centroids(self, data):\n",
    "#         \"\"\"Randomly Initialise Centroids\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         data: array or matrix, number_rows, number_features\n",
    "        \n",
    "#         Returns\n",
    "#         --------\n",
    "#         centroids: array of k centroids chosen as random data points \n",
    "#         \"\"\"\n",
    "        \n",
    "#         initial_centroids = np.random.permutation(data.shape[0])[:self.k]\n",
    "#         self.centroids = data[initial_centroids]\n",
    "\n",
    "#         return self.centroids\n",
    "    \n",
    "    \n",
    "#     def assign_clusters(self, data):\n",
    "#         \"\"\"Compute distance of data from clusters and assign data point\n",
    "#            to closest cluster.\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         data: array or matrix, number_rows, number_features\n",
    "        \n",
    "#         Returns\n",
    "#         --------\n",
    "#         cluster_labels: index which minmises the distance of data to each\n",
    "#         cluster\n",
    "            \n",
    "#         \"\"\"\n",
    "        \n",
    "#         if data.ndim == 1:\n",
    "#             data = data.reshape(-1, 1)\n",
    "        \n",
    "#         dist_to_centroid =  pairwise_distances(data, self.centroids, metric = 'euclidean')\n",
    "#         self.cluster_labels = np.argmin(dist_to_centroid, axis = 1)\n",
    "        \n",
    "#         return  self.cluster_labels\n",
    "    \n",
    "    \n",
    "#     def update_centroids(self, data):\n",
    "#         \"\"\"Computes average of all data points in cluster and\n",
    "#            assigns new centroids as average of data points\n",
    "        \n",
    "#         Parameters\n",
    "#         -----------\n",
    "#         data: array or matrix, number_rows, number_features\n",
    "        \n",
    "#         Returns\n",
    "#         -----------\n",
    "#         centroids: array, k, number_features\n",
    "#         \"\"\"\n",
    "        \n",
    "#         self.centroids = np.array([data[self.cluster_labels == i].mean(axis = 0) for i in range(self.k)])\n",
    "        \n",
    "#         return self.centroids\n",
    "    \n",
    "    \n",
    "#     def convergence_calculation(self):\n",
    "#         \"\"\"\n",
    "#         Calculates \n",
    "        \n",
    "#         \"\"\"\n",
    "#         pass\n",
    "    \n",
    "#     def predict(self, data):\n",
    "#         \"\"\"Predict which cluster data point belongs to\n",
    "        \n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         data: array or matrix, number_rows, number_features\n",
    "        \n",
    "#         Returns\n",
    "#         --------\n",
    "#         cluster_labels: index which minmises the distance of data to each\n",
    "#         cluster\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return self.assign_clusters(data)\n",
    "    \n",
    "#     def fit_kmeans(self, data):\n",
    "#         \"\"\"\n",
    "#         This function contains the main loop to fit the algorithm\n",
    "#         Implements initialise centroids and update_centroids\n",
    "#         according to max_iter\n",
    "#         -----------------------\n",
    "        \n",
    "#         Returns\n",
    "#         -------\n",
    "#         instance of kmeans class\n",
    "            \n",
    "#         \"\"\"\n",
    "#         self.centroids = self.initialise_centroids(data)\n",
    "        \n",
    "#         # Main kmeans loop\n",
    "#         for iter in range(self.max_iter):\n",
    "\n",
    "#             self.cluster_labels = self.assign_clusters(data)\n",
    "#             self.centroids = self.update_centroids(data)          \n",
    "#             if iter % 100 == 0:\n",
    "#                 print(\"Running Model Iteration %d \" %iter)\n",
    "#         print(\"Model finished running\")\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_blobs\n",
    "# # create blobs\n",
    "# data = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=1.6, random_state=50)\n",
    "# # create np array for data points\n",
    "# points = data[0]\n",
    "# # create scatter plot\n",
    "# plt.scatter(data[0][:,0], data[0][:,1], c=data[1], cmap='viridis')\n",
    "# plt.xlim(-15,15)\n",
    "# plt.ylim(-15,15)\n",
    "\n",
    "# X = data[0]\n",
    "# X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# from sklearn.cluster import KMeans \n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.corpus import stopwords\n",
    "# from bs4 import BeautifulSoup\n",
    "# from scipy.stats import multivariate_normal as mvn\n",
    "# import nltk\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import string\n",
    "# # Input data files are available in the \"../input/\" directory.\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# # email module has some useful functions\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
